{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f52c4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Obt√©m o caminho absoluto do diret√≥rio raiz do projeto (supondo que este notebook esteja em uma subpasta)\n",
    "root_path = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Sobe um n√≠vel\n",
    "if root_path not in sys.path:\n",
    "    sys.path.append(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd95fa5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from src.services.finbert import FinBERT\n",
    "from src.services.news_search import NewsSearch\n",
    "from src.services.sentiment_aggregator import SentimentAggregator\n",
    "from src.services.market_data_fetcher import MarketDataFetcher\n",
    "from src.services.sentiment_market_analyzer import SentimentMarketAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f56ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_path = r\"C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\"\n",
    "inference_path = r\"C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\inferred\"\n",
    "averages_path = r\"C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\averages\"\n",
    "market_data_path = r\"C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\market_data\"\n",
    "results_path = r\"C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\results\"\n",
    "\n",
    "TICKERS = [\n",
    "        \"AAPL\",        # Apple\n",
    "        \"MSFT\",        # Microsoft\n",
    "        \"TSLA\",        # Tesla\n",
    "        \"GOOGL\",       # Google\n",
    "        \"NVDA\",        # Nvidia\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc7080fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Buscando not√≠cias de AAPL, de 2025-09-01 a 2025-10-31\n",
      "‚úÖ Arquivo atualizado: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_AAPL.csv\n",
      "\n",
      "üîç Buscando not√≠cias de MSFT, de 2025-09-01 a 2025-10-31\n",
      "‚úÖ Arquivo atualizado: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_MSFT.csv\n",
      "\n",
      "üîç Buscando not√≠cias de TSLA, de 2025-09-01 a 2025-10-31\n",
      "‚úÖ Arquivo atualizado: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_TSLA.csv\n",
      "\n",
      "üîç Buscando not√≠cias de GOOGL, de 2025-09-01 a 2025-10-31\n",
      "‚úÖ Arquivo atualizado: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_GOOGL.csv\n",
      "\n",
      "üîç Buscando not√≠cias de NVDA, de 2025-09-01 a 2025-10-31\n",
      "‚úÖ Arquivo atualizado: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_NVDA.csv\n"
     ]
    }
   ],
   "source": [
    "fetcher = NewsSearch(TICKERS, raw_path)\n",
    "fetcher.fetch_and_save_news()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "971e4189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 13:47</td>\n",
       "      <td>Prediction: Taiwan Semiconductor Manufacturing...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://finnhub.io/api/news?id=b8724e9fdbb6de2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 11:17</td>\n",
       "      <td>Wall Street Brunch: Big Banks Kick Off Earning...</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>https://finnhub.io/api/news?id=920cfdc6d3c6b80...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 06:30</td>\n",
       "      <td>Why You Shouldn‚Äôt Buy an iPhone Right Now</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://finnhub.io/api/news?id=c8c8dd85fe98cb5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 05:35</td>\n",
       "      <td>Will a Leadership Change Be Enough to Turn App...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://finnhub.io/api/news?id=371544169f0cfbf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 05:14</td>\n",
       "      <td>Claret Asset Management Q2 2025 Quarterly Letter</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>https://finnhub.io/api/news?id=084614435e8f57e...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker              Date                                              Title  \\\n",
       "0   AAPL  2025-07-13 13:47  Prediction: Taiwan Semiconductor Manufacturing...   \n",
       "1   AAPL  2025-07-13 11:17  Wall Street Brunch: Big Banks Kick Off Earning...   \n",
       "2   AAPL  2025-07-13 06:30          Why You Shouldn‚Äôt Buy an iPhone Right Now   \n",
       "3   AAPL  2025-07-13 05:35  Will a Leadership Change Be Enough to Turn App...   \n",
       "4   AAPL  2025-07-13 05:14   Claret Asset Management Q2 2025 Quarterly Letter   \n",
       "\n",
       "         Source                                                URL  \n",
       "0         Yahoo  https://finnhub.io/api/news?id=b8724e9fdbb6de2...  \n",
       "1  SeekingAlpha  https://finnhub.io/api/news?id=920cfdc6d3c6b80...  \n",
       "2         Yahoo  https://finnhub.io/api/news?id=c8c8dd85fe98cb5...  \n",
       "3         Yahoo  https://finnhub.io/api/news?id=371544169f0cfbf...  \n",
       "4  SeekingAlpha  https://finnhub.io/api/news?id=084614435e8f57e...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_csv(os.path.join(raw_path + f'\\\\news_{\"AAPL\"}.csv'))\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b084ab15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processando: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_AAPL.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classificando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 976/976 [00:39<00:00, 25.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo em: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\inferred\\news_AAPL.csv\n",
      "Processando: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_GOOGL.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classificando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 975/975 [00:45<00:00, 21.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo em: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\inferred\\news_GOOGL.csv\n",
      "Processando: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_MSFT.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classificando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 987/987 [00:41<00:00, 23.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo em: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\inferred\\news_MSFT.csv\n",
      "Processando: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_NVDA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classificando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 987/987 [00:50<00:00, 19.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo em: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\inferred\\news_NVDA.csv\n",
      "Processando: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\raw\\news_TSLA.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Classificando: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 973/973 [00:39<00:00, 24.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Salvo em: C:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\data\\inferred\\news_TSLA.csv\n"
     ]
    }
   ],
   "source": [
    "finbert = FinBERT(raw_path, inference_path)\n",
    "finbert.infer_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c075a684",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th>Title</th>\n",
       "      <th>Source</th>\n",
       "      <th>URL</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 13:47</td>\n",
       "      <td>Prediction: Taiwan Semiconductor Manufacturing...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://finnhub.io/api/news?id=b8724e9fdbb6de2...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 11:17</td>\n",
       "      <td>Wall Street Brunch: Big Banks Kick Off Earning...</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>https://finnhub.io/api/news?id=920cfdc6d3c6b80...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 06:30</td>\n",
       "      <td>Why You Shouldn‚Äôt Buy an iPhone Right Now</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://finnhub.io/api/news?id=c8c8dd85fe98cb5...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 05:35</td>\n",
       "      <td>Will a Leadership Change Be Enough to Turn App...</td>\n",
       "      <td>Yahoo</td>\n",
       "      <td>https://finnhub.io/api/news?id=371544169f0cfbf...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2025-07-13 05:14</td>\n",
       "      <td>Claret Asset Management Q2 2025 Quarterly Letter</td>\n",
       "      <td>SeekingAlpha</td>\n",
       "      <td>https://finnhub.io/api/news?id=084614435e8f57e...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Ticker              Date                                              Title  \\\n",
       "0   AAPL  2025-07-13 13:47  Prediction: Taiwan Semiconductor Manufacturing...   \n",
       "1   AAPL  2025-07-13 11:17  Wall Street Brunch: Big Banks Kick Off Earning...   \n",
       "2   AAPL  2025-07-13 06:30          Why You Shouldn‚Äôt Buy an iPhone Right Now   \n",
       "3   AAPL  2025-07-13 05:35  Will a Leadership Change Be Enough to Turn App...   \n",
       "4   AAPL  2025-07-13 05:14   Claret Asset Management Q2 2025 Quarterly Letter   \n",
       "\n",
       "         Source                                                URL Sentiment  \n",
       "0         Yahoo  https://finnhub.io/api/news?id=b8724e9fdbb6de2...  Positive  \n",
       "1  SeekingAlpha  https://finnhub.io/api/news?id=920cfdc6d3c6b80...   Neutral  \n",
       "2         Yahoo  https://finnhub.io/api/news?id=c8c8dd85fe98cb5...   Neutral  \n",
       "3         Yahoo  https://finnhub.io/api/news?id=371544169f0cfbf...   Neutral  \n",
       "4  SeekingAlpha  https://finnhub.io/api/news?id=084614435e8f57e...   Neutral  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news = pd.read_csv(os.path.join(inference_path + f'\\\\news_{\"AAPL\"}.csv'))\n",
    "df_news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c59e6aa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[‚úî] M√©dia por dia:\n",
      "      Ticker        Date  Average_Daily_Score\n",
      "0  news_AAPL  2025-07-07            -0.200000\n",
      "1  news_AAPL  2025-07-08            -0.090909\n",
      "2  news_AAPL  2025-07-09             0.246154\n",
      "3  news_AAPL  2025-07-10             0.306122\n",
      "4  news_AAPL  2025-07-11             0.176471\n",
      "\n",
      "[‚úî] M√©dia por quinzena:\n",
      "       Ticker YearMonth Biweekly  Score_Medio_Quinzena\n",
      "0   news_AAPL   2025-07        1              0.131356\n",
      "1   news_AAPL   2025-10        2              0.214865\n",
      "2  news_GOOGL   2025-07        1              0.131356\n",
      "3  news_GOOGL   2025-10        2              0.246279\n",
      "4   news_MSFT   2025-07        1              0.259259\n",
      "\n",
      "[‚úî] M√©dia por m√™s:\n",
      "       Ticker YearMonth  Average_Monthly_Score\n",
      "0   news_AAPL   2025-07               0.131356\n",
      "1   news_AAPL   2025-10               0.214865\n",
      "2  news_GOOGL   2025-07               0.131356\n",
      "3  news_GOOGL   2025-10               0.246279\n",
      "4   news_MSFT   2025-07               0.259259\n",
      "\n",
      "[üíæ] Resultados salvos em CSV.\n"
     ]
    }
   ],
   "source": [
    "agregador = SentimentAggregator(inference_path, averages_path)\n",
    "agregador.process()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10c83926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• Coletando dados para news_AAPL de 2025-07-07 a 2025-10-31...\n",
      "Erro ao baixar pre√ßos para news_AAPL: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
      "\n",
      "üì• Coletando dados para news_GOOGL de 2025-07-02 a 2025-10-31...\n",
      "Erro ao baixar pre√ßos para news_GOOGL: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
      "\n",
      "üì• Coletando dados para news_MSFT de 2025-07-06 a 2025-10-31...\n",
      "Erro ao baixar pre√ßos para news_MSFT: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
      "\n",
      "üì• Coletando dados para news_NVDA de 2021-04-25 a 2025-10-31...\n",
      "Erro ao baixar pre√ßos para news_NVDA: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n",
      "\n",
      "üì• Coletando dados para news_TSLA de 2020-06-12 a 2025-10-31...\n",
      "Erro ao baixar pre√ßos para news_TSLA: Invalid API call. Please retry or visit the documentation (https://www.alphavantage.co/documentation/) for TIME_SERIES_DAILY.\n"
     ]
    }
   ],
   "source": [
    "daily_avg_path = os.path.join(averages_path, 'daily_avg.csv')\n",
    "\n",
    "fetcher = MarketDataFetcher(market_data_path, daily_avg_path)\n",
    "fetcher.fetch_and_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5831da42",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Missing column provided to 'parse_dates': 'Data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m analyzer = \u001b[43mSentimentMarketAnalyzer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdaily_avg_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarket_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresults_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m analyzer.executar()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\src\\services\\sentiment_market_analyzer.py:36\u001b[39m, in \u001b[36mSentimentMarketAnalyzer.__init__\u001b[39m\u001b[34m(self, sentiment_csv, market_data_dir, output_dir)\u001b[39m\n\u001b[32m     33\u001b[39m os.makedirs(\u001b[38;5;28mself\u001b[39m.output_dir, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     35\u001b[39m \u001b[38;5;66;03m# Carrega todos os dados de sentimento di√°rio\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m \u001b[38;5;28mself\u001b[39m.df_sent = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43msentiment_csv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mData\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:161\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m    155\u001b[39m         \u001b[38;5;28mself\u001b[39m._validate_usecols_names(\n\u001b[32m    156\u001b[39m             usecols,\n\u001b[32m    157\u001b[39m             \u001b[38;5;28mself\u001b[39m.names,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    158\u001b[39m         )\n\u001b[32m    160\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_parse_dates_presence\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnames\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[32m    162\u001b[39m \u001b[38;5;28mself\u001b[39m._set_noconvert_columns()\n\u001b[32m    164\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcelo\\Documents\\Code\\tcc-sentiment-analysis\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\base_parser.py:243\u001b[39m, in \u001b[36mParserBase._validate_parse_dates_presence\u001b[39m\u001b[34m(self, columns)\u001b[39m\n\u001b[32m    233\u001b[39m missing_cols = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\n\u001b[32m    234\u001b[39m     \u001b[38;5;28msorted\u001b[39m(\n\u001b[32m    235\u001b[39m         {\n\u001b[32m   (...)\u001b[39m\u001b[32m    240\u001b[39m     )\n\u001b[32m    241\u001b[39m )\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m missing_cols:\n\u001b[32m--> \u001b[39m\u001b[32m243\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    244\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMissing column provided to \u001b[39m\u001b[33m'\u001b[39m\u001b[33mparse_dates\u001b[39m\u001b[33m'\u001b[39m\u001b[33m: \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmissing_cols\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    245\u001b[39m     )\n\u001b[32m    246\u001b[39m \u001b[38;5;66;03m# Convert positions to actual column names\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [\n\u001b[32m    248\u001b[39m     col \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(col, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns) \u001b[38;5;28;01melse\u001b[39;00m columns[col]\n\u001b[32m    249\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m cols_needed\n\u001b[32m    250\u001b[39m ]\n",
      "\u001b[31mValueError\u001b[39m: Missing column provided to 'parse_dates': 'Data'"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentMarketAnalyzer(daily_avg_path, market_data_path, results_path) \n",
    "analyzer.executar()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
